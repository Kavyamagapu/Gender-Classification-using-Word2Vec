{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classification using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = pd.read_csv('male.txt',sep='\\t')\n",
    "female = pd.read_csv('female.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2819, 1), (2629, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male.shape,female.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "male['labels'] = 1\n",
    "female['labels'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.concat([male,female],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Busy but a good quality hotel. Would stay again.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clean, Friendly, Modern Hotel As per the title...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great time in the Dominican I went with my now...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decent enough hotel I have mixed feelings abou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Convenient When I say Above Average I'm compar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>Fantastic Location, can't beat it! I recently ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5444</th>\n",
       "      <td>Fabulous Location, Chic Hotel! Hotel Granados ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5445</th>\n",
       "      <td>Beautiful Resort........food not so good My hu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5446</th>\n",
       "      <td>Great Break We went to The Gallery in Barcelon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>Very Friendly Budget Hotel. We (my mum and I )...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5448 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  labels\n",
       "0      Busy but a good quality hotel. Would stay again.       1\n",
       "1     Clean, Friendly, Modern Hotel As per the title...       1\n",
       "2     Great time in the Dominican I went with my now...       1\n",
       "3     Decent enough hotel I have mixed feelings abou...       1\n",
       "4     Convenient When I say Above Average I'm compar...       1\n",
       "...                                                 ...     ...\n",
       "5443  Fantastic Location, can't beat it! I recently ...       0\n",
       "5444  Fabulous Location, Chic Hotel! Hotel Granados ...       0\n",
       "5445  Beautiful Resort........food not so good My hu...       0\n",
       "5446  Great Break We went to The Gallery in Barcelon...       0\n",
       "5447  Very Friendly Budget Hotel. We (my mum and I )...       0\n",
       "\n",
       "[5448 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kavya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kavya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kavya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kavya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []           # Corpus is preprocessed Reviews\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GENSIM \n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import keyedvectors\n",
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]       # List of lists containing words in Reviews \n",
    "for sent in corpus:\n",
    "    sent_token=sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "        words.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['busy', 'good', 'quality', 'hotel', 'would', 'stay'], 5448)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0],len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.insert(1, 'Processed_Review', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Processed_Review</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Busy but a good quality hotel. Would stay again.</td>\n",
       "      <td>[busy, good, quality, hotel, would, stay]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clean, Friendly, Modern Hotel As per the title...</td>\n",
       "      <td>[clean, friendly, modern, hotel, per, title, h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great time in the Dominican I went with my now...</td>\n",
       "      <td>[great, time, dominican, went, fiance, propose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decent enough hotel I have mixed feelings abou...</td>\n",
       "      <td>[decent, enough, hotel, mixed, feeling, stay, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Convenient When I say Above Average I'm compar...</td>\n",
       "      <td>[convenient, say, average, comparing, sparse, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0   Busy but a good quality hotel. Would stay again.   \n",
       "1  Clean, Friendly, Modern Hotel As per the title...   \n",
       "2  Great time in the Dominican I went with my now...   \n",
       "3  Decent enough hotel I have mixed feelings abou...   \n",
       "4  Convenient When I say Above Average I'm compar...   \n",
       "\n",
       "                                    Processed_Review  labels  \n",
       "0          [busy, good, quality, hotel, would, stay]       1  \n",
       "1  [clean, friendly, modern, hotel, per, title, h...       1  \n",
       "2  [great, time, dominican, went, fiance, propose...       1  \n",
       "3  [decent, enough, hotel, mixed, feeling, stay, ...       1  \n",
       "4  [convenient, say, average, comparing, sparse, ...       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the label column\n",
    "messages['label'] = messages['labels'].map({1:1,0:0})\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split (messages['Processed_Review'], messages['label'] , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['busy', 'good', 'quality', 'hotel', 'would', 'stay'], 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=300,\n",
    "                                   window=5,\n",
    "                                   min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18182791, 20082550)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(X_train,total_examples=w2v_model.corpus_count,epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('complain', 0.3286914527416229),\n",
       " ('terrible', 0.31816184520721436),\n",
       " ('dylan', 0.31191787123680115),\n",
       " ('wrong', 0.30868852138519287),\n",
       " ('poor', 0.30851513147354126),\n",
       " ('horrible', 0.3081361949443817),\n",
       " ('funny', 0.30722224712371826),\n",
       " ('upset', 0.3066122531890869),\n",
       " ('lacking', 0.2877514362335205),\n",
       " ('sorry', 0.2872674763202667)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.5598031282424927),\n",
       " ('excellent', 0.4896434545516968),\n",
       " ('decent', 0.439590722322464),\n",
       " ('reasonable', 0.34724682569503784),\n",
       " ('superb', 0.34139809012413025),\n",
       " ('amazing', 0.3379555940628052),\n",
       " ('poor', 0.33348435163497925),\n",
       " ('nice', 0.3302851617336273),\n",
       " ('best', 0.319502055644989),\n",
       " ('variable', 0.3161775469779968)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.43692314624786377)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding vector forms for sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = set(w2v_model.wv.index_to_key )\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in word]) for ls in X_train],dtype=object)\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in word]) for ls in X_test],dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(300, dtype=float))\n",
    "        \n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(300, dtype=float))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Random_forest = RandomForestClassifier()\n",
    "Random_model = Random_forest.fit(X_train_vect_avg, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = Random_model.predict(X_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.626 / Recall: 0.626 / Accuracy: 0.6256880733944954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,accuracy_score\n",
    "precision = precision_score(y_test, y_pred,average= 'micro')\n",
    "recall = recall_score(y_test, y_pred,average= 'micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), accuracy))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support vector classifier\"  \n",
    "svm = SVC()  \n",
    "sv_model = svm.fit(X_train_vect_avg, y_train.values.ravel())  \n",
    "y_pred = sv_model.predict(X_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.656 / Recall: 0.656 / Accuracy: 0.6559633027522935\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred,average= 'micro')\n",
    "recall = recall_score(y_test, y_pred,average= 'micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>True Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC_AUC_Score</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model Name, True Positive, False Negative, False Positive, True Negative, Accuracy, Precision, Recall, F1 Score, Specificity, MCC, ROC_AUC_Score, Balanced Accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSResults = pd.DataFrame(columns=['Model Name','True Positive',\t'False Negative',\t'False Positive',\t'True Negative',\t'Accuracy',\t'Precision',\t'Recall',\t'F1 Score',\t'Specificity',\t'MCC',\t'ROC_AUC_Score',\t'Balanced Accuracy'])\n",
    "CSResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kavya\\AppData\\Local\\Temp\\ipykernel_1812\\3788807022.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  CSResults = CSResults.append(new_row,ignore_index=True)\n",
      "C:\\Users\\kavya\\AppData\\Local\\Temp\\ipykernel_1812\\3788807022.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  CSResults = CSResults.append(new_row,ignore_index=True)\n",
      "C:\\Users\\kavya\\AppData\\Local\\Temp\\ipykernel_1812\\3788807022.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  CSResults = CSResults.append(new_row,ignore_index=True)\n",
      "C:\\Users\\kavya\\AppData\\Local\\Temp\\ipykernel_1812\\3788807022.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  CSResults = CSResults.append(new_row,ignore_index=True)\n",
      "C:\\Users\\kavya\\AppData\\Local\\Temp\\ipykernel_1812\\3788807022.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  CSResults = CSResults.append(new_row,ignore_index=True)\n",
      "C:\\Users\\kavya\\AppData\\Local\\Temp\\ipykernel_1812\\3788807022.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  CSResults = CSResults.append(new_row,ignore_index=True)\n",
      "C:\\Users\\kavya\\AppData\\Local\\Temp\\ipykernel_1812\\3788807022.py:90: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  CSResults = CSResults.append(new_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "# Build the model\n",
    "modelXGB = XGBClassifier(n_estimators=100, max_depth=3, eval_metric='mlogloss')\n",
    "\n",
    "bankdataSVM = SVC(C=1.0, kernel='linear', degree=3, gamma='scale', coef0=0.0, shrinking=True, \n",
    "                  probability=True, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                  max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "ModelKNN = KNeighborsClassifier(n_neighbors=5)\n",
    "modelGNB = GaussianNB()\n",
    "ModelLR = LogisticRegression()\n",
    "ModelDC = DecisionTreeClassifier()\n",
    "ModelRF = RandomForestClassifier()\n",
    "ModelET = ExtraTreesClassifier()\n",
    "\n",
    "# Evalution matrix for all the algorithm\n",
    "\n",
    "MM = [ModelLR, ModelDC, ModelRF, ModelET, modelGNB, ModelKNN, bankdataSVM]\n",
    "for models in MM:\n",
    "            \n",
    "    # Train the model training dataset\n",
    "    \n",
    "    models.fit(X_train_vect_avg, y_train.values)\n",
    "    \n",
    "    # Prediction the model with test dataset\n",
    "    \n",
    "    y_pred = models.predict(X_test_vect_avg)\n",
    "    y_pred_prob = models.predict_proba(X_test_vect_avg)\n",
    "\n",
    "    \n",
    "    # confusion matrix in sklearn\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # actual values\n",
    "\n",
    "    actual = y_test\n",
    "\n",
    "    # predicted values\n",
    "\n",
    "    predicted = y_pred\n",
    "\n",
    "    tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "    # calculating the metrics\n",
    "\n",
    "    sensitivity = round(tp/(tp+fn), 3);\n",
    "    specificity = round(tn/(tn+fp), 3);\n",
    "    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "    precision = round(tp/(tp+fp), 3);\n",
    "    f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "    # Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "    # A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "    from math import sqrt\n",
    "\n",
    "    mx = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "    MCC = round(((tp * tn) - (fp * fn)) / sqrt(mx), 3)\n",
    "\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "    #------------------------------------------------------\n",
    "    new_row = {'Model Name' : models,\n",
    "               'True Positive': tp,\n",
    "               'False Negative': fn, \n",
    "               'False Positive': fp, \n",
    "               'True Negative': tn,\n",
    "               'Accuracy' : accuracy,\n",
    "               'Precision' : precision,\n",
    "               'Recall' : sensitivity,\n",
    "               'F1 Score' : f1Score,\n",
    "               'Specificity' : specificity,\n",
    "               'MCC': MCC,\n",
    "               'ROC_AUC_Score':roc_auc_score(actual, y_pred),\n",
    "               'Balanced Accuracy':balanced_accuracy}\n",
    "    CSResults = CSResults.append(new_row,ignore_index=True)\n",
    "    #------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>True Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC_AUC_Score</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>393</td>\n",
       "      <td>191</td>\n",
       "      <td>190</td>\n",
       "      <td>316</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.648726</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>333</td>\n",
       "      <td>251</td>\n",
       "      <td>233</td>\n",
       "      <td>273</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.554866</td>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>364</td>\n",
       "      <td>220</td>\n",
       "      <td>194</td>\n",
       "      <td>312</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.619944</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ExtraTreeClassifier(random_state=755008496), ...</td>\n",
       "      <td>366</td>\n",
       "      <td>218</td>\n",
       "      <td>232</td>\n",
       "      <td>274</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.584107</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>445</td>\n",
       "      <td>139</td>\n",
       "      <td>324</td>\n",
       "      <td>182</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.560835</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>360</td>\n",
       "      <td>224</td>\n",
       "      <td>258</td>\n",
       "      <td>248</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.553278</td>\n",
       "      <td>0.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>397</td>\n",
       "      <td>187</td>\n",
       "      <td>181</td>\n",
       "      <td>325</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.661044</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name True Positive  \\\n",
       "0                               LogisticRegression()           393   \n",
       "1                           DecisionTreeClassifier()           333   \n",
       "2  (DecisionTreeClassifier(max_features='auto', r...           364   \n",
       "3  (ExtraTreeClassifier(random_state=755008496), ...           366   \n",
       "4                                       GaussianNB()           445   \n",
       "5                             KNeighborsClassifier()           360   \n",
       "6             SVC(kernel='linear', probability=True)           397   \n",
       "\n",
       "  False Negative False Positive True Negative  Accuracy  Precision  Recall  \\\n",
       "0            191            190           316     0.650      0.674   0.673   \n",
       "1            251            233           273     0.556      0.588   0.570   \n",
       "2            220            194           312     0.620      0.652   0.623   \n",
       "3            218            232           274     0.587      0.612   0.627   \n",
       "4            139            324           182     0.575      0.579   0.762   \n",
       "5            224            258           248     0.558      0.583   0.616   \n",
       "6            187            181           325     0.662      0.687   0.680   \n",
       "\n",
       "   F1 Score  Specificity    MCC  ROC_AUC_Score  Balanced Accuracy  \n",
       "0     0.674        0.625  0.297       0.648726              0.649  \n",
       "1     0.579        0.540  0.110       0.554866              0.555  \n",
       "2     0.637        0.617  0.239       0.619944              0.620  \n",
       "3     0.619        0.542  0.169       0.584107              0.584  \n",
       "4     0.658        0.360  0.133       0.560835              0.561  \n",
       "5     0.599        0.490  0.107       0.553278              0.553  \n",
       "6     0.683        0.642  0.322       0.661044              0.661  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSResults.to_csv('CsResults.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "  sample_corpus = []\n",
    "  for i in range(0, 1):\n",
    "    # review = review.str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\" \")\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sample)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    sample_corpus.append(review)\n",
    "    \n",
    "  sample_words=[]\n",
    "  for sent in sample_corpus:\n",
    "    sent_token = sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "        sample_words.append(simple_preprocess(sent))\n",
    "  # return sample_words\n",
    "  return w2v_model.wv[sample_words[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):\n",
    "  return np.mean(list(doc),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPredict(s):\n",
    "    if Random_model.predict(s) == [0]:\n",
    "        return \"FEMALE\"\n",
    "    else:\n",
    "        return \"MALE\"\n",
    "def SPredict(s):\n",
    "    if sv_model.predict(s) == [0]:\n",
    "        return \"FEMALE\"\n",
    "    else:\n",
    "        return \"MALE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Prediction :  MALE\n",
      "SVM Prediction :  MALE\n",
      "LogisticRegression :  [1]\n",
      "DecisionTreeClassifier :  [1]\n",
      "ExtraTreesClassifier :  [1]\n",
      "GaussianNB :  [1]\n",
      "KNeighborsClassifier :  [1]\n"
     ]
    }
   ],
   "source": [
    "s = avg_word2vec(preprocess('Busy but a good quality hotel. Would stay again.'))\n",
    "s = s.reshape(1,-1)\n",
    "\n",
    "print(\"Random Forest Prediction : \",RPredict(s))\n",
    "print(\"SVM Prediction : \", SPredict(s))\n",
    "print(\"LogisticRegression : \",ModelLR.predict(s))\n",
    "print(\"DecisionTreeClassifier : \",ModelDC.predict(s))\n",
    "print(\"ExtraTreesClassifier : \",ModelET.predict(s))\n",
    "print(\"GaussianNB : \",modelGNB.predict(s))\n",
    "print(\"KNeighborsClassifier : \",ModelKNN.predict(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Prediction :  FEMALE\n",
      "SVM Prediction :  FEMALE\n",
      "LogisticRegression :  [0]\n",
      "DecisionTreeClassifier :  [1]\n",
      "ExtraTreesClassifier :  [0]\n",
      "GaussianNB :  [0]\n",
      "KNeighborsClassifier :  [1]\n"
     ]
    }
   ],
   "source": [
    "s = avg_word2vec(preprocess('''Without doubt one of the favorite place I stayed during my \"Solo Travel time in\".Eco Resort has great rooms with excellent services and location was also a bonus. Proprietor himself takes care of the guests. Very friendly and competent staff, extremely helpful yet never intrusive.\n",
    "I stayed here for 5 days. My room was big, clean and very comfortable, the view from my room was of snow covered mountains. It felt like, I was the only person staying there, very relaxing, very calm, very serene.\n",
    "I would highly recommend to everybody, especially for any FEMALE SOLO TRAVELER! It's a true sample of excellent hospitality.\n",
    "Thank you again Eco Resort for going just that little step extra for the guests!!!'''))\n",
    "s = s.reshape(1,-1)\n",
    "\n",
    "print(\"Random Forest Prediction : \",RPredict(s))\n",
    "print(\"SVM Prediction : \", SPredict(s))\n",
    "print(\"LogisticRegression : \",ModelLR.predict(s))\n",
    "print(\"DecisionTreeClassifier : \",ModelDC.predict(s))\n",
    "print(\"ExtraTreesClassifier : \",ModelET.predict(s))\n",
    "print(\"GaussianNB : \",modelGNB.predict(s))\n",
    "print(\"KNeighborsClassifier : \",ModelKNN.predict(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
